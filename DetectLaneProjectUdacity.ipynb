{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] >>>> Building video test_videos_output/challenge.mp4\n",
      "[MoviePy] Writing video test_videos_output/challenge.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/251 [00:00<?, ?it/s]\u001b[A\n",
      "  1%|          | 2/251 [00:00<00:15, 15.70it/s]\u001b[A\n",
      "  2%|▏         | 4/251 [00:00<00:15, 16.35it/s]\u001b[A\n",
      "  2%|▏         | 6/251 [00:00<00:14, 17.29it/s]\u001b[A\n",
      "  3%|▎         | 8/251 [00:00<00:14, 17.30it/s]\u001b[A\n",
      "  4%|▍         | 10/251 [00:00<00:14, 16.14it/s]\u001b[A\n",
      "  5%|▍         | 12/251 [00:00<00:14, 16.65it/s]\u001b[A\n",
      "  6%|▌         | 15/251 [00:00<00:13, 18.00it/s]\u001b[A\n",
      "  7%|▋         | 18/251 [00:00<00:11, 19.70it/s]\u001b[A\n",
      "  8%|▊         | 21/251 [00:01<00:10, 21.28it/s]\u001b[A\n",
      " 10%|▉         | 24/251 [00:01<00:10, 21.52it/s]\u001b[A\n",
      " 11%|█         | 27/251 [00:01<00:10, 22.12it/s]\u001b[A\n",
      " 12%|█▏        | 30/251 [00:01<00:10, 21.35it/s]\u001b[A\n",
      " 13%|█▎        | 33/251 [00:01<00:10, 21.80it/s]\u001b[A\n",
      " 14%|█▍        | 36/251 [00:01<00:09, 22.22it/s]\u001b[A\n",
      " 16%|█▌        | 39/251 [00:01<00:09, 22.77it/s]\u001b[A\n",
      " 17%|█▋        | 42/251 [00:01<00:08, 23.33it/s]\u001b[A\n",
      " 18%|█▊        | 45/251 [00:02<00:09, 22.56it/s]\u001b[A\n",
      " 19%|█▉        | 48/251 [00:02<00:10, 20.03it/s]\u001b[A\n",
      " 20%|██        | 51/251 [00:02<00:12, 16.50it/s]\u001b[A\n",
      " 21%|██        | 53/251 [00:02<00:12, 15.38it/s]\u001b[A\n",
      " 22%|██▏       | 55/251 [00:02<00:14, 13.71it/s]\u001b[A\n",
      " 23%|██▎       | 57/251 [00:03<00:14, 13.10it/s]\u001b[A\n",
      " 24%|██▎       | 59/251 [00:03<00:15, 12.59it/s]\u001b[A\n",
      " 24%|██▍       | 61/251 [00:03<00:15, 12.51it/s]\u001b[A\n",
      " 25%|██▌       | 63/251 [00:03<00:15, 12.43it/s]\u001b[A\n",
      " 26%|██▌       | 65/251 [00:03<00:17, 10.47it/s]\u001b[A\n",
      " 27%|██▋       | 67/251 [00:04<00:18, 10.05it/s]\u001b[A\n",
      " 27%|██▋       | 69/251 [00:04<00:18,  9.87it/s]\u001b[A\n",
      " 28%|██▊       | 71/251 [00:04<00:18,  9.67it/s]\u001b[A\n",
      " 29%|██▉       | 73/251 [00:04<00:16, 10.50it/s]\u001b[A\n",
      " 30%|██▉       | 75/251 [00:04<00:16, 10.89it/s]\u001b[A\n",
      " 31%|███       | 77/251 [00:04<00:15, 11.28it/s]\u001b[A\n",
      " 31%|███▏      | 79/251 [00:05<00:15, 10.90it/s]\u001b[A\n",
      " 32%|███▏      | 81/251 [00:05<00:15, 11.23it/s]\u001b[A\n",
      " 33%|███▎      | 83/251 [00:05<00:14, 11.46it/s]\u001b[A\n",
      " 34%|███▍      | 85/251 [00:05<00:14, 11.53it/s]\u001b[A\n",
      " 35%|███▍      | 87/251 [00:05<00:13, 11.78it/s]\u001b[A\n",
      " 35%|███▌      | 89/251 [00:06<00:13, 11.85it/s]\u001b[A\n",
      " 36%|███▋      | 91/251 [00:06<00:13, 12.10it/s]\u001b[A\n",
      " 37%|███▋      | 93/251 [00:06<00:13, 11.85it/s]\u001b[A\n",
      " 38%|███▊      | 95/251 [00:06<00:13, 11.98it/s]\u001b[A\n",
      " 39%|███▊      | 97/251 [00:06<00:12, 12.26it/s]\u001b[A\n",
      " 39%|███▉      | 99/251 [00:06<00:12, 11.93it/s]\u001b[A\n",
      " 40%|████      | 101/251 [00:06<00:12, 12.14it/s]\u001b[A\n",
      " 41%|████      | 103/251 [00:07<00:11, 12.34it/s]\u001b[A\n",
      " 42%|████▏     | 105/251 [00:07<00:11, 12.23it/s]\u001b[A\n",
      " 43%|████▎     | 107/251 [00:07<00:12, 11.84it/s]\u001b[A\n",
      " 43%|████▎     | 109/251 [00:07<00:11, 12.42it/s]\u001b[A\n",
      " 44%|████▍     | 111/251 [00:07<00:11, 11.95it/s]\u001b[A\n",
      " 45%|████▌     | 113/251 [00:07<00:11, 12.08it/s]\u001b[A\n",
      " 46%|████▌     | 115/251 [00:08<00:11, 12.32it/s]\u001b[A\n",
      " 47%|████▋     | 117/251 [00:08<00:11, 12.11it/s]\u001b[A\n",
      " 47%|████▋     | 119/251 [00:08<00:10, 12.02it/s]\u001b[A\n",
      " 48%|████▊     | 121/251 [00:08<00:11, 11.64it/s]\u001b[A\n",
      " 49%|████▉     | 123/251 [00:08<00:11, 11.46it/s]\u001b[A\n",
      " 50%|████▉     | 125/251 [00:09<00:12,  9.82it/s]\u001b[A\n",
      " 51%|█████     | 127/251 [00:09<00:13,  9.38it/s]\u001b[A\n",
      " 51%|█████     | 128/251 [00:09<00:13,  8.94it/s]\u001b[A\n",
      " 51%|█████▏    | 129/251 [00:09<00:13,  8.92it/s]\u001b[A\n",
      " 52%|█████▏    | 130/251 [00:09<00:13,  8.68it/s]\u001b[A\n",
      " 53%|█████▎    | 132/251 [00:09<00:13,  8.99it/s]\u001b[A\n",
      " 53%|█████▎    | 134/251 [00:10<00:12,  9.59it/s]\u001b[A\n",
      " 54%|█████▍    | 136/251 [00:10<00:11,  9.90it/s]\u001b[A\n",
      " 55%|█████▍    | 138/251 [00:10<00:11,  9.75it/s]\u001b[A\n",
      " 55%|█████▌    | 139/251 [00:10<00:12,  9.32it/s]\u001b[A\n",
      " 56%|█████▌    | 140/251 [00:10<00:12,  9.20it/s]\u001b[A\n",
      " 57%|█████▋    | 142/251 [00:10<00:11,  9.77it/s]\u001b[A\n",
      " 57%|█████▋    | 144/251 [00:11<00:10, 10.40it/s]\u001b[A\n",
      " 58%|█████▊    | 146/251 [00:11<00:10, 10.36it/s]\u001b[A\n",
      " 59%|█████▉    | 148/251 [00:11<00:09, 10.57it/s]\u001b[A\n",
      " 60%|█████▉    | 150/251 [00:11<00:09, 10.77it/s]\u001b[A\n",
      " 61%|██████    | 152/251 [00:11<00:08, 11.26it/s]\u001b[A\n",
      " 61%|██████▏   | 154/251 [00:11<00:08, 11.07it/s]\u001b[A\n",
      " 62%|██████▏   | 156/251 [00:12<00:08, 11.34it/s]\u001b[A\n",
      " 63%|██████▎   | 158/251 [00:12<00:08, 11.17it/s]\u001b[A\n",
      " 64%|██████▎   | 160/251 [00:12<00:08, 10.89it/s]\u001b[A\n",
      " 65%|██████▍   | 162/251 [00:12<00:09,  9.68it/s]\u001b[A\n",
      " 65%|██████▌   | 164/251 [00:12<00:09,  9.50it/s]\u001b[A\n",
      " 66%|██████▌   | 166/251 [00:13<00:08, 10.01it/s]\u001b[A\n",
      " 67%|██████▋   | 168/251 [00:13<00:08, 10.36it/s]\u001b[A\n",
      " 68%|██████▊   | 170/251 [00:13<00:08,  9.63it/s]\u001b[A\n",
      " 68%|██████▊   | 171/251 [00:13<00:08,  9.49it/s]\u001b[A\n",
      " 69%|██████▉   | 173/251 [00:13<00:07,  9.86it/s]\u001b[A\n",
      " 70%|██████▉   | 175/251 [00:14<00:07, 10.16it/s]\u001b[A\n",
      " 71%|███████   | 177/251 [00:14<00:07,  9.87it/s]\u001b[A\n",
      " 71%|███████▏  | 179/251 [00:14<00:06, 10.42it/s]\u001b[A\n",
      " 72%|███████▏  | 181/251 [00:14<00:06, 10.09it/s]\u001b[A\n",
      " 73%|███████▎  | 183/251 [00:14<00:06, 10.98it/s]\u001b[A\n",
      " 74%|███████▎  | 185/251 [00:14<00:06, 10.76it/s]\u001b[A\n",
      " 75%|███████▍  | 187/251 [00:15<00:05, 10.70it/s]\u001b[A\n",
      " 75%|███████▌  | 189/251 [00:15<00:05, 10.63it/s]\u001b[A\n",
      " 76%|███████▌  | 191/251 [00:15<00:05, 10.14it/s]\u001b[A\n",
      " 77%|███████▋  | 193/251 [00:15<00:05, 10.42it/s]\u001b[A\n",
      " 78%|███████▊  | 195/251 [00:15<00:05, 10.44it/s]\u001b[A\n",
      " 78%|███████▊  | 197/251 [00:16<00:04, 10.83it/s]\u001b[A\n",
      " 79%|███████▉  | 199/251 [00:16<00:04, 10.56it/s]\u001b[A\n",
      " 80%|████████  | 201/251 [00:16<00:04, 10.74it/s]\u001b[A\n",
      " 81%|████████  | 203/251 [00:16<00:04, 10.83it/s]\u001b[A\n",
      " 82%|████████▏ | 205/251 [00:16<00:04, 11.02it/s]\u001b[A\n",
      " 82%|████████▏ | 207/251 [00:17<00:03, 11.27it/s]\u001b[A\n",
      " 83%|████████▎ | 209/251 [00:17<00:03, 11.19it/s]\u001b[A\n",
      " 84%|████████▍ | 211/251 [00:17<00:03, 11.34it/s]\u001b[A\n",
      " 85%|████████▍ | 213/251 [00:17<00:03, 11.23it/s]\u001b[A\n",
      " 86%|████████▌ | 215/251 [00:17<00:03, 11.32it/s]\u001b[A\n",
      " 86%|████████▋ | 217/251 [00:17<00:03, 10.26it/s]\u001b[A\n",
      " 87%|████████▋ | 219/251 [00:18<00:03, 10.65it/s]\u001b[A\n",
      " 88%|████████▊ | 221/251 [00:18<00:02, 10.63it/s]\u001b[A\n",
      " 89%|████████▉ | 223/251 [00:18<00:02, 10.82it/s]\u001b[A\n",
      " 90%|████████▉ | 225/251 [00:18<00:02,  9.84it/s]\u001b[A\n",
      " 90%|█████████ | 227/251 [00:18<00:02,  9.42it/s]\u001b[A\n",
      " 91%|█████████ | 228/251 [00:19<00:02,  9.12it/s]\u001b[A\n",
      " 92%|█████████▏| 230/251 [00:19<00:02,  9.13it/s]\u001b[A\n",
      " 92%|█████████▏| 232/251 [00:19<00:01,  9.96it/s]\u001b[A\n",
      " 93%|█████████▎| 234/251 [00:19<00:01, 10.21it/s]\u001b[A\n",
      " 94%|█████████▍| 236/251 [00:19<00:01, 10.22it/s]\u001b[A\n",
      " 95%|█████████▍| 238/251 [00:20<00:01, 10.92it/s]\u001b[A\n",
      " 96%|█████████▌| 240/251 [00:20<00:00, 11.37it/s]\u001b[A\n",
      " 96%|█████████▋| 242/251 [00:20<00:00, 10.31it/s]\u001b[A\n",
      " 97%|█████████▋| 244/251 [00:20<00:00, 10.65it/s]\u001b[A\n",
      " 98%|█████████▊| 246/251 [00:20<00:00,  8.82it/s]\u001b[A\n",
      " 98%|█████████▊| 247/251 [00:21<00:00,  8.63it/s]\u001b[A\n",
      " 99%|█████████▉| 249/251 [00:21<00:00,  9.19it/s]\u001b[A\n",
      "100%|█████████▉| 250/251 [00:21<00:00,  8.88it/s]\u001b[A\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] Done.\n",
      "[MoviePy] >>>> Video ready: test_videos_output/challenge.mp4 \n",
      "\n",
      "CPU times: user 8.34 s, sys: 2.94 s, total: 11.3 s\n",
      "Wall time: 23.9 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<video width=\"960\" height=\"540\" controls>\n",
       "  <source src=\"test_videos_output/challenge.mp4\">\n",
       "</video>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import everything needed to edit/save/watch video clips\n",
    "from moviepy.editor import VideoFileClip\n",
    "from IPython.display import HTML\n",
    "def process_image(image):\n",
    "    import matplotlib.pyplot as plt\n",
    "    import matplotlib.image as mpimg\n",
    "    import numpy as np\n",
    "    import cv2\n",
    "    import math\n",
    "    import os\n",
    "    %matplotlib inline\n",
    "\n",
    "    #reading in an image\n",
    "    imshape = image.shape\n",
    "    # definig x,y boundaries of our region of ineterst\n",
    "    #bottom Y coordinate\n",
    "    by= imshape[0]\n",
    "    #top Y coordinate\n",
    "    ty=int(math.floor(imshape[0]*.6))\n",
    "    #left x coordinate\n",
    "    lx= int(math.floor(imshape[1]*.15))\n",
    "    #right x coordinate\n",
    "    rx= int(math.floor(imshape[1]*.95))\n",
    "    #top left x coordinate\n",
    "    tlx= int(math.floor(imshape[1]*.45))\n",
    "    #top right x coordinate\n",
    "    trx= int(math.floor(imshape[1]*.55))\n",
    "    #declaring variable to hold the value of left line and right line of last frame in case we cant detect any suitable line in current frame \n",
    "    oldleftline=np.zeros(shape=(1,4), dtype=np.int64)\n",
    "    oldrightline=np.zeros(shape=(1,4), dtype=np.int64)\n",
    "\n",
    "    #printing out some stats and plotting\n",
    "    #plt.imshow(image)  # if you wanted to show a single color channel image called 'gray', for example, call as plt.imshow(gray, cmap='gray')\n",
    "    def grayscale(img):\n",
    "        \"\"\"Applies the Grayscale transform\n",
    "        This will return an image with only one color channel\n",
    "        but NOTE: to see the returned image as grayscale\n",
    "        (assuming your grayscaled image is called 'gray')\n",
    "        you should call plt.imshow(gray, cmap='gray')\"\"\"\n",
    "        return cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "        # Or use BGR2GRAY if you read an image with cv2.imread()\n",
    "        # return cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    def canny(img, low_threshold, high_threshold):\n",
    "        \"\"\"Applies the Canny transform\"\"\"\n",
    "        return cv2.Canny(img, low_threshold, high_threshold)\n",
    "\n",
    "    def gaussian_blur(img, kernel_size):\n",
    "        \"\"\"Applies a Gaussian Noise kernel\"\"\"\n",
    "        return cv2.GaussianBlur(img, (kernel_size, kernel_size), 0)\n",
    "\n",
    "    def region_of_interest(img, vertices):\n",
    "        \"\"\"\n",
    "        Applies an image mask.\n",
    "\n",
    "        Only keeps the region of the image defined by the polygon\n",
    "        formed from `vertices`. The rest of the image is set to black.\n",
    "        \"\"\"\n",
    "        #defining a blank mask to start with\n",
    "        mask = np.zeros_like(img)   \n",
    "\n",
    "        #defining a 3 channel or 1 channel color to fill the mask with depending on the input image\n",
    "        if len(img.shape) > 2:\n",
    "            channel_count = img.shape[2]  # i.e. 3 or 4 depending on your image\n",
    "            ignore_mask_color = (255,) * channel_count\n",
    "        else:\n",
    "            ignore_mask_color = 255\n",
    "\n",
    "        #filling pixels inside the polygon defined by \"vertices\" with the fill color    \n",
    "        cv2.fillPoly(mask, vertices, ignore_mask_color)\n",
    "\n",
    "        #returning the image only where mask pixels are nonzero\n",
    "        masked_image = cv2.bitwise_and(img, mask)\n",
    "        #print(masked_image.shape)\n",
    "        return masked_image\n",
    "    #function to identify two lane lines from the current frame detected lines data using hough transform\n",
    "    def two_lines (lines):\n",
    "        global oldleftline\n",
    "        global oldrightline\n",
    "        leftline = []\n",
    "        rightline = []\n",
    "        for line in lines:\n",
    "            for x1,y1,x2,y2 in line:\n",
    "                #calculating line equation with in the form of x = my + c\n",
    "                #i did not use y = mx + c becuase there is a possibility that lane line is perpendicular to x axis therefore m will be infinite\n",
    "                if (y1==y2):\n",
    "                    continue\n",
    "                m=((x2 - x1)/(y2-y1))\n",
    "                c=(x2-(m*y2))\n",
    "                #coordinates of intersection of this line with bottom and top boundary\n",
    "                lnbx = int(math.floor((m*by) + c))\n",
    "                lntx = int(math.floor((m*ty) + c))\n",
    "                # removing noise excluding lines which are out of defined region\n",
    "                if ((lnbx < lx) or (lnbx > rx) or (lntx < tlx) or (lntx > trx)):\n",
    "                    continue\n",
    "                #checking if line is left line or right line\n",
    "                if (lnbx < tlx):\n",
    "                    leftline.append([lnbx,by,lntx,ty])\n",
    "                else:\n",
    "                    rightline.append([lnbx,by,lntx,ty])\n",
    "        # taking median of all the lane lines detected, if lines not detected on one of the sides then old value will be taken\n",
    "        if (len(leftline) > 0):\n",
    "            leftlineends=(np.median(np.asarray(leftline,dtype=np.int64),axis=0).astype(np.int64))\n",
    "            oldleftline = leftlineends\n",
    "        else:\n",
    "            leftlineends = oldleftline\n",
    "        if (len(rightline) > 0):\n",
    "            rightlineends= (np.median(np.asarray(rightline,dtype=np.int64),axis=0).astype(np.int64))\n",
    "            oldrightline = rightlineends\n",
    "        else:\n",
    "            rightlineends = oldrightline\n",
    "        return np.stack((leftlineends,rightlineends)) \n",
    "        \n",
    "    def draw_lines(img, lines, color=[255, 0, 0], thickness=12):\n",
    "        \"\"\"\n",
    "        NOTE: this is the function you might want to use as a starting point once you want to \n",
    "        average/extrapolate the line segments you detect to map out the full\n",
    "        extent of the lane (going from the result shown in raw-lines-example.mp4\n",
    "        to that shown in P1_example.mp4).  \n",
    "\n",
    "        Think about things like separating line segments by their \n",
    "        slope ((y2-y1)/(x2-x1)) to decide which segments are part of the left\n",
    "        line vs. the right line.  Then, you can average the position of each of \n",
    "        the lines and extrapolate to the top and bottom of the lane.\n",
    "\n",
    "        This function draws `lines` with `color` and `thickness`.    \n",
    "        Lines are drawn on the image inplace (mutates the image).\n",
    "        If you want to make the lines semi-transparent, think about combining\n",
    "        this function with the weighted_img() function below\n",
    "        \"\"\"\n",
    "        for line in lines:\n",
    "            #for x1,y1,x2,y2 in line:\n",
    "            cv2.line(img, (line[0], line[1]), (line[2], line[3]), color, thickness)\n",
    "            #cv2.line(img, (x1,y1),(x2,y2), color, thickness)\n",
    "\n",
    "    def hough_lines(img, rho, theta, threshold, min_line_len, max_line_gap):\n",
    "        \"\"\"\n",
    "        `img` should be the output of a Canny transform.\n",
    "\n",
    "        Returns an image with hough lines drawn.\n",
    "        \"\"\"\n",
    "        lines = cv2.HoughLinesP(img, rho, theta, threshold, np.array([]), minLineLength=min_line_len, maxLineGap=max_line_gap)\n",
    "        line_img = np.zeros((img.shape[0], img.shape[1], 3), dtype=np.uint8)\n",
    "        lines2 = two_lines(lines)\n",
    "        draw_lines(line_img, lines2)\n",
    "        return line_img\n",
    "\n",
    "    # Python 3 has support for cool math symbols.\n",
    "\n",
    "    def weighted_img(img, initial_img, α=0.8, β=1., λ=0.):\n",
    "        \"\"\"\n",
    "        `img` is the output of the hough_lines(), An image with lines drawn on it.\n",
    "        Should be a blank image (all black) with lines drawn on it.\n",
    "\n",
    "        `initial_img` should be the image before any processing.\n",
    "\n",
    "        The result image is computed as follows:\n",
    "\n",
    "        initial_img * α + img * β + λ\n",
    "        NOTE: initial_img and img must be the same shape!\n",
    "        \"\"\"\n",
    "        return cv2.addWeighted(initial_img, α, img, β, λ)\n",
    "    vertices = np.array([[(lx,by),(tlx, ty), (trx, ty), (rx,by)]], dtype=np.int32)\n",
    "    #print(vertices)\n",
    "    rho = 1 # distance resolution in pixels of the Hough grid\n",
    "    theta = np.pi/180 # angular resolution in radians of the Hough grid\n",
    "    threshold = 15     # minimum number of votes (intersections in Hough grid cell)\n",
    "    min_line_len = 40 #minimum number of pixels making up a line\n",
    "    max_line_gap = 20    # maximum gap in pixels between connectable line segments\n",
    "    line_image = np.copy(image)*0 # creating a blank to draw lines on\n",
    "    region1=region_of_interest(canny(gaussian_blur(grayscale(image),3), 50, 150),vertices)\n",
    "    img2=weighted_img(hough_lines(region1, rho, theta, threshold, min_line_len, max_line_gap), image)\n",
    "    return(img2)\n",
    "white_output = 'test_videos_output/challenge.mp4'\n",
    "## To speed up the testing process you may want to try your pipeline on a shorter subclip of the video\n",
    "## To do so add .subclip(start_second,end_second) to the end of the line below\n",
    "## Where start_second and end_second are integer values representing the start and end of the subclip\n",
    "## You may also uncomment the following line for a subclip of the first 5 seconds\n",
    "##clip1 = VideoFileClip(\"test_videos/solidWhiteRight.mp4\").subclip(0,.1)\n",
    "clip1 = VideoFileClip(\"test_videos/challenge.mp4\").subclip(0,10)\n",
    "white_clip = clip1.fl_image(process_image) #NOTE: this function expects color images!!\n",
    "%time white_clip.write_videofile(white_output, audio=False)\n",
    "HTML(\"\"\"\n",
    "<video width=\"960\" height=\"540\" controls>\n",
    "  <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format(white_output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
